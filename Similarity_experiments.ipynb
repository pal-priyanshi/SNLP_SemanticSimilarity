{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cdcc00e",
   "metadata": {},
   "source": [
    "JSON structure-- {\"text\": \"[INST] <<SYS>>\\nFor the given two sentences, classify them as semantically similar with 'yes' or 'no'\\n<</SYS>>\\n\\nSentence 1: A plane is taking off.\\nSentence 2: An air plane is taking off.\\nAre they semantically similar?:\\n[/INST]Response:yes\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f61b5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c011133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06873bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['captions', 'meta-data1', 'meta-data2', 'meta-data3', 'similarity_score', 'Sentence1', 'Sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a18917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_train_json = pd.read_json('Dataset/sts/sts-train.json',lines=True)\n",
    "sts_test_json = pd.read_json('Dataset/sts/sts-test.json',lines=True)\n",
    "sts_train = pd.read_csv('Dataset/sts/sts-train.csv', sep=\"\\t\", header=None, names=column_names)\n",
    "sts_test = pd.read_csv('Dataset/sts/sts-test.csv', sep=\"\\t\", header=None, names=column_names)\n",
    "msr_train_json = pd.read_json('Dataset/msr_latest/msr-train.json',lines=True)\n",
    "msr_test_json = pd.read_json('Dataset/msr_latest/msr-test.json',lines=True)\n",
    "qqp_train_json = pd.read_json('Dataset/qqp/qqp-train.json',lines=True)\n",
    "qqp_test_json = pd.read_json('Dataset/qqp/qqp-test.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67f1eedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sts_train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb470119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nFor the given two sentences, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nFor the given two sentences, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nFor the given two sentences, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nFor the given two sentences, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[INST] &lt;&lt;SYS&gt;&gt;\\nFor the given two sentences, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [INST] <<SYS>>\\nFor the given two sentences, c...\n",
       "1  [INST] <<SYS>>\\nFor the given two sentences, c...\n",
       "2  [INST] <<SYS>>\\nFor the given two sentences, c...\n",
       "3  [INST] <<SYS>>\\nFor the given two sentences, c...\n",
       "4  [INST] <<SYS>>\\nFor the given two sentences, c..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_train_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "00ae6d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(passed_json):\n",
    "    pattern = r'\\w+|[^\\w\\s]+'\n",
    "    total_common_count=0\n",
    "    total_noncommon_count=0\n",
    "    sentence1_array=[]\n",
    "    sentence2_array=[]\n",
    "    target_output=[]\n",
    "    for i in passed_json[\"text\"]:\n",
    "        S1= re.search(r\"Sentence 1:(.*)\",i).group(1)\n",
    "        S2= re.search(r\"Sentence 2:(.*)\",i).group(1)\n",
    "        response = re.search(r\"Response:(.*)\",i).group(1)\n",
    "        sentence1_array.append(S1)\n",
    "        sentence2_array.append(S2)\n",
    "        target_output.append(1 if response == \"yes\" else 0)\n",
    "        #punctuations = [char for char in S1 if char in string.punctuation]\n",
    "       # print(punctuations)\n",
    "        #punct.extend(punctuations)\n",
    "        #S1 = re.sub()\n",
    "        s1_tokens = re.findall(pattern, S1)\n",
    "        s2_tokens = re.findall(pattern, S2)\n",
    "\n",
    "        S1.lower()\n",
    "        S2.lower()\n",
    "        s1_tokens = re.findall(pattern, S1)\n",
    "        s2_tokens = re.findall(pattern, S2)\n",
    "\n",
    "        counter1 = Counter(s1_tokens)\n",
    "        counter2 = Counter(s2_tokens)\n",
    "\n",
    "        # Find common elements and their counts\n",
    "        common_elements_count = (counter1 & counter2).items()\n",
    "        unique_to_list1 = counter1 - counter2\n",
    "        unique_to_list2 = counter2 - counter1\n",
    "\n",
    "        # Combine the results to mimic the symmetric difference\n",
    "        unique_elements = unique_to_list1 + unique_to_list2\n",
    "\n",
    "        non_common = sum(unique_elements.values())\n",
    "        total_noncommon_count += non_common\n",
    "        # Calculate the total number of common elements\n",
    "        total_common = sum(min(counter1[element], counter2[element]) for element in (counter1 & counter2))\n",
    "        total_common_count += total_common\n",
    "    return sentence1_array,sentence2_array, target_output, total_common_count, total_noncommon_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3e0d627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_train_s1, sts_train_s2, sts_target_output_train, sts_commoncount_train, sts_noncommoncount_train=preprocessing(sts_train_json)\n",
    "sts_test_s1, sts_test_s2, sts_target_output_test, sts_commoncount_test, sts_noncommoncount_test=preprocessing(sts_test_json)\n",
    "msr_train_s1, msr_train_s2, msr_target_output_train, msr_commoncount_train, msr_noncommoncount_train=preprocessing(msr_train_json)\n",
    "msr_test_s1, msr_test_s2, msr_target_output_test, msr_commoncount_test, msr_noncommoncount_test=preprocessing(msr_test_json)\n",
    "qqp_train_s1, qqp_train_s2, qqp_target_output_train, qqp_commoncount_train, qqp_noncommoncount_train=preprocessing(qqp_train_json)\n",
    "qqp_test_s1, qqp_test_s2, qqp_target_output_test, qqp_commoncount_test, qqp_noncommoncount_test=preprocessing(qqp_test_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f54b89f",
   "metadata": {},
   "source": [
    "Common and non common words in STS\n",
    "\n",
    "Common and non common words in MSR\n",
    "\n",
    "Common and non common words in QQP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d4764b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46440 72319\n",
      "88363 86436\n",
      "29967 68888\n"
     ]
    }
   ],
   "source": [
    "print(sts_commoncount_train+sts_commoncount_test, sts_noncommoncount_train+sts_noncommoncount_test)\n",
    "print(msr_commoncount_train+msr_commoncount_test, msr_noncommoncount_train+msr_noncommoncount_test)\n",
    "print(qqp_commoncount_train+qqp_commoncount_test, qqp_noncommoncount_train+qqp_noncommoncount_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1a82b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_tfidf(s1,s2):\n",
    "    # Combine the sentences into one list for vectorization\n",
    "    all_sentences = s1 + s2\n",
    "\n",
    "    # Initialize a TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit and transform the sentences\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_sentences)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    #cos_sim = cosine_similarity([vec_sentence1], [vec_sentence2])[0][0]\n",
    "\n",
    "    # Define a threshold\n",
    "    threshold = 0.5\n",
    "    # Generate embeddings\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(all_sentences)\n",
    "\n",
    "    # Now, each pair of sentences at the same index can be compared\n",
    "    similarities_tf = []\n",
    "    similarities_sbert = []\n",
    "    for i in range(len(s1)):\n",
    "        # Compute cosine similarity between corresponding sentence pairs for TF-IDF\n",
    "        sim_score_tf = cosine_similarity(tfidf_matrix[i], tfidf_matrix[len(s1) + i])[0][0]\n",
    "        \n",
    "        # Compute cosine similarity between corresponding sentence pairs for SBERT\n",
    "        sim_score_sbert = cosine_similarity(\n",
    "            embeddings[i].reshape(1, -1),  # Reshape embeddings to 2D\n",
    "            embeddings[len(s1) + i].reshape(1, -1)  # Reshape embeddings to 2D\n",
    "        )[0][0]\n",
    "\n",
    "        # Append the binarized similarity scores\n",
    "        similarities_tf.append(1 if sim_score_tf >= threshold else 0)\n",
    "        similarities_sbert.append(1 if sim_score_sbert >= threshold else 0)\n",
    "\n",
    "    return similarities_tf, similarities_sbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8d6e386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_train_simtf,sts_train_simsbert= get_sim_tfidf(sts_train_s1,sts_train_s2)\n",
    "sts_test_simtf, sts_test_simsbert= get_sim_tfidf(sts_test_s1,sts_test_s2)\n",
    "msr_train_simtf, msr_train_simsbert= get_sim_tfidf(msr_train_s1,msr_train_s2)\n",
    "msr_test_simtf, msr_test_simsbert= get_sim_tfidf(msr_test_s1,msr_test_s2)\n",
    "qqp_train_simtf, qqp_train_simsbert= get_sim_tfidf(qqp_train_s1,qqp_train_s2)\n",
    "qqp_test_simtf, qqp_test_simsbert= get_sim_tfidf(qqp_test_s1,qqp_test_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e3e87054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(target_output, similarities, title):\n",
    "\n",
    "    conf_matrix = confusion_matrix(target_output, similarities)\n",
    "    #print(\"Confusion Matrix:\")\n",
    "    #print(conf_matrix)\n",
    "    #disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['No', 'Yes'])\n",
    "    #disp.plot(cmap=plt.cm.Blues)\n",
    "    #plt.title(title)\n",
    "    #plt.show()\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(target_output, similarities)\n",
    "    recall = recall_score(target_output, similarities)\n",
    "    f1 = f1_score(target_output, similarities)\n",
    "    acc_score = accuracy_score(target_output, similarities)\n",
    "\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "    print(f\"Accuracy Score: {acc_score:.2f}\")\n",
    "    print(\"#####\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced70229",
   "metadata": {},
   "source": [
    "Let's see how 3 datasets vary in similarity(cosine), when the tfidf/Sbert is fitted for only train data. \n",
    "1) First, let's check accuracy of similarity for the train data of the three datasets (SBERT representation)\n",
    "2) check accuracy of similarity for the test data of the three datasets (SBERT representation)\n",
    "\n",
    "3) check accuracy of similarity for the train data of the three datasets (tf-idf representation) \n",
    "4) check accuracy of similarity for the test data of the three datasets (tf-idf representation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e5d99b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.67\n",
      "Recall: 0.98\n",
      "F1 Score: 0.80\n",
      "Accuracy Score: 0.74\n",
      "#####\n",
      "Precision: 0.70\n",
      "Recall: 0.99\n",
      "F1 Score: 0.82\n",
      "Accuracy Score: 0.70\n",
      "#####\n",
      "Precision: 0.49\n",
      "Recall: 1.00\n",
      "F1 Score: 0.65\n",
      "Accuracy Score: 0.60\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "get_scores(sts_target_output_train,sts_train_simsbert, \"Consufion matrix of train data -- SBERT -- STS\")\n",
    "#get_scores(sts_target_output_test,sts_test_simsbert)\n",
    "\n",
    "get_scores(msr_target_output_train,msr_train_simsbert, \"Consufion matrix of train data -- SBERT -- MSR\")\n",
    "#get_scores(msr_target_output_test,msr_test_simsbert)\n",
    "\n",
    "get_scores(qqp_target_output_train,qqp_train_simsbert, \"Consufion matrix of train data -- SBERT -- QQP\")\n",
    "#get_scores(qqp_target_output_test,qqp_test_simsbert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984105f4",
   "metadata": {},
   "source": [
    "### TEST DATA - SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "25864cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.68\n",
      "Recall: 0.96\n",
      "F1 Score: 0.80\n",
      "Accuracy Score: 0.76\n",
      "#####\n",
      "Precision: 0.68\n",
      "Recall: 0.99\n",
      "F1 Score: 0.81\n",
      "Accuracy Score: 0.69\n",
      "#####\n",
      "Precision: 0.35\n",
      "Recall: 1.00\n",
      "F1 Score: 0.51\n",
      "Accuracy Score: 0.35\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "\n",
    "get_scores(sts_target_output_test,sts_test_simsbert, \"Confusion matrix of test data -- SBERT -- STS\")\n",
    "\n",
    "get_scores(msr_target_output_test,msr_test_simsbert, \"Confusion matrix of test data -- SBERT -- MSR\")\n",
    "\n",
    "get_scores(qqp_target_output_test,qqp_test_simsbert, \"Confusion matrix of test data -- SBERT -- QQP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e205ad9",
   "metadata": {},
   "source": [
    "### TRAIN - TFIDF REPRESENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2daacb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.78\n",
      "Recall: 0.74\n",
      "F1 Score: 0.76\n",
      "Accuracy Score: 0.75\n",
      "#####\n",
      "Precision: 0.74\n",
      "Recall: 0.89\n",
      "F1 Score: 0.81\n",
      "Accuracy Score: 0.71\n",
      "#####\n",
      "Precision: 0.54\n",
      "Recall: 0.71\n",
      "F1 Score: 0.61\n",
      "Accuracy Score: 0.66\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "get_scores(sts_target_output_train,sts_train_simtf, \"Consufion matrix of train data -- TF-IDF -- STS\")\n",
    "#get_scores(sts_target_output_test,sts_test_simsbert)\n",
    "\n",
    "get_scores(msr_target_output_train,msr_train_simtf, \"Consufion matrix of train data -- TF-IDF -- MSR\")\n",
    "#get_scores(msr_target_output_test,msr_test_simsbert)\n",
    "\n",
    "get_scores(qqp_target_output_train,qqp_train_simtf, \"Consufion matrix of train data -- TF-IDF -- QQP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "386042dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.76\n",
      "Recall: 0.72\n",
      "F1 Score: 0.74\n",
      "Accuracy Score: 0.75\n",
      "#####\n",
      "Precision: 0.73\n",
      "Recall: 0.90\n",
      "F1 Score: 0.81\n",
      "Accuracy Score: 0.71\n",
      "#####\n",
      "Precision: 0.35\n",
      "Recall: 1.00\n",
      "F1 Score: 0.51\n",
      "Accuracy Score: 0.35\n",
      "#####\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "get_scores(sts_target_output_test,sts_test_simtf, \"Consufion matrix of test data -- TF-IDF -- STS\")\n",
    "#get_scores(sts_target_output_test,sts_test_simsbert)\n",
    "\n",
    "get_scores(msr_target_output_test,msr_test_simtf, \"Consufion matrix of test data -- TF-IDF -- MSR\")\n",
    "#get_scores(msr_target_output_test,msr_test_simsbert)\n",
    "\n",
    "get_scores(qqp_target_output_test,qqp_test_simtf, \"Consufion matrix of test data -- TF-IDF -- QQP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed5ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
